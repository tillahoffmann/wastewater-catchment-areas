{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import shapely\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 144\n",
    "mpl.style.use('scrartcl.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the data we need.\n",
    "ROOT = pathlib.Path('data/wastewater_catchment_areas_public')\n",
    "\n",
    "lsoas = gpd.read_file('data/geoportal.statistics.gov.uk/LSOA11_BGC.zip').set_index('LSOA11CD')\n",
    "\n",
    "catchments = gpd.read_file(ROOT / 'catchments_consolidated.shp')\n",
    "\n",
    "lsoa_catchment_lookup = pd.read_csv(ROOT / 'lsoa_catchment_lookup.csv')\n",
    "\n",
    "lsoa_coverage = pd.read_csv(ROOT / 'lsoa_coverage.csv')\n",
    "\n",
    "lsoa_population = pd.read_csv('data/ons.gov.uk/lsoa_syoa_all_years_t.csv',\n",
    "                              usecols=['LSOA11CD', 'year', 'Pop_Total'])\n",
    "lsoa_population['year'] = lsoa_population.year.apply(lambda x: int(x[4:]))\n",
    "\n",
    "waterbase_catchment_lookup = pd.read_csv(ROOT / 'waterbase_catchment_lookup.csv')\n",
    "\n",
    "waterbase_consolidated = pd.read_csv(ROOT / 'waterbase_consolidated.csv',\n",
    "                                     index_col=['uwwCode', 'year'])\n",
    "# Fix a data problem where someone dropped a zero (or another digit) for Kinmel Bay.\n",
    "waterbase_consolidated.loc[('UKWAWA_WW_TP000093', 2016), 'uwwLoadEnteringUWWTP'] *= 10\n",
    "\n",
    "# Add up the treated load for the two works in Abingdon (which should really just be one).\n",
    "x = waterbase_consolidated.loc['UKENTH_TWU_TP000001'].uwwLoadEnteringUWWTP\n",
    "y = waterbase_consolidated.loc['UKENTH_TWU_TP000165'].uwwLoadEnteringUWWTP\n",
    "z = y.reindex(x.index).fillna(0) + x\n",
    "waterbase_consolidated.loc['UKENTH_TWU_TP000001', 'uwwLoadEnteringUWWTP'] = z.values\n",
    "\n",
    "# Get rid of the duplicate treatment work.\n",
    "waterbase_consolidated = waterbase_consolidated.drop('UKENTH_TWU_TP000165', level=0)\n",
    "waterbase_consolidated = waterbase_consolidated.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the total intersection area for each LSOA.\n",
    "intersection_area_sum = lsoa_catchment_lookup.groupby('LSOA11CD')\\\n",
    "    .intersection_area.sum().reset_index(name='intersection_area_sum')\n",
    "\n",
    "# Construct a data frame that has a number of different areas that we can use for normalisation.\n",
    "merged = pd.merge(lsoa_coverage, intersection_area_sum, on='LSOA11CD')\n",
    "merged = pd.merge(merged, lsoa_catchment_lookup, on='LSOA11CD')\n",
    "merged = pd.merge(merged, lsoa_population, on='LSOA11CD')\n",
    "\n",
    "def aggregate(subset):\n",
    "    # Construct different normalisations.\n",
    "    norms = {\n",
    "        'norm_total_area': subset.total_area,\n",
    "        'norm_area_covered': subset.area_covered,\n",
    "        'norm_intersection_sum': subset.intersection_area_sum,\n",
    "    }\n",
    "    intersection_area_pop = subset.intersection_area * subset.Pop_Total\n",
    "    return pd.Series({key: (intersection_area_pop / value).sum() for key, value in norms.items()})\n",
    "\n",
    "grouped = merged.groupby(['identifier', 'year'])\n",
    "geospatial_estimate = grouped.apply(aggregate)\n",
    "geospatial_estimate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show population estimates by company.\n",
    "merged = pd.merge(catchments, geospatial_estimate.reset_index(), on=['identifier'])\n",
    "totals = merged[merged.year == 2016].groupby('company').norm_area_covered.sum()\n",
    "print(f'total population served: {totals.sum() / 1e6:.3f}m')\n",
    "totals / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the waterbase data (BOD p.e.) with geospatial population estimates for comparison.\n",
    "merged = pd.merge(waterbase_catchment_lookup, waterbase_consolidated, on=['uwwCode', 'uwwName'])\n",
    "merged = pd.merge(merged, geospatial_estimate, on=['year', 'identifier'])\n",
    "\n",
    "# Sum by year and uwwCode (because the same treatment work may be linked to multiple catchments if\n",
    "# the subcatchment aggregation didn't work out properly). Then assign back to the merged dataset and\n",
    "# drop duplicates.\n",
    "estimates = merged.groupby(['uwwCode', 'year']).agg({\n",
    "    'norm_total_area': 'sum',\n",
    "    'norm_area_covered': 'sum',\n",
    "})\n",
    "for key in estimates:\n",
    "    merged[key] = [estimates.loc[(x.uwwCode, x.year), key] for _, x in merged.iterrows()]\n",
    "merged = merged.drop_duplicates(['uwwCode', 'year'])\n",
    "\n",
    "# Drop treatment works for Scotland and Southwest water because we don't have\n",
    "# LSOAs and catchments for them, respectively.\n",
    "merged = merged[~merged.uwwCode.str.startswith('UKSC')]\n",
    "merged = merged[~merged.uwwCode.str.startswith('UKENSW_SWS')]\n",
    "\n",
    "# Evaluate the pearson correlation on the log scale (omitting treatment works without load).\n",
    "f = merged.uwwLoadEnteringUWWTP > 0\n",
    "stats.pearsonr(np.log(merged.uwwLoadEnteringUWWTP[f]), np.log(merged.norm_area_covered[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a figure of different population estimates for a given year.\n",
    "fig = plt.figure()\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "ax = fig.add_subplot(gs[:, 0])\n",
    "year = 2016\n",
    "subset = merged[merged.year == year]\n",
    "ax.scatter(subset.uwwLoadEnteringUWWTP, subset.norm_area_covered, marker='.', alpha=.5)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "lims = subset.uwwLoadEnteringUWWTP.quantile([0, 1])\n",
    "ax.plot(lims, lims, color='k', ls=':')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('BOD person equivalent')\n",
    "ax.set_ylabel('Geospatial population estimate')\n",
    "ax.text(0.05, 0.95, '(a)', transform=ax.transAxes, va='top')\n",
    "\n",
    "# Annotations.\n",
    "annotations = [\n",
    "    {\n",
    "        'code': 'UKENNE_NU_TP000026',\n",
    "        'label': 'Haggerston',\n",
    "        'xfactor': 3,\n",
    "        'yfactor': 1,\n",
    "    },\n",
    "    {\n",
    "        'code': 'UKWAWA_WW_TP000016',\n",
    "        'label': 'Rotherwas',\n",
    "        'xfactor': 2.5,\n",
    "    },\n",
    "    {\n",
    "        'code': 'UKENAN_AW_TP000020',\n",
    "        'label': 'Billericay',\n",
    "        'xfactor': 2/3,\n",
    "        'yfactor': 3,\n",
    "        'kwargs': {'ha': 'center'},\n",
    "    },\n",
    "    {\n",
    "        'code': 'UKENAN_AW_TP000051',\n",
    "        'label': 'Chalton',\n",
    "        'xfactor': 1 / 3,\n",
    "        'kwargs': {'ha': 'right'},\n",
    "    },\n",
    "]\n",
    "indexed = subset.set_index('uwwCode')\n",
    "for annotation in annotations:\n",
    "    item = indexed.loc[annotation['code']]\n",
    "\n",
    "    ax.annotate(\n",
    "        annotation['label'],\n",
    "        (item.uwwLoadEnteringUWWTP, item.norm_area_covered),\n",
    "        (item.uwwLoadEnteringUWWTP * annotation.get('xfactor', 1),\n",
    "            item.norm_area_covered * annotation.get('yfactor', 1)),\n",
    "        arrowprops={\n",
    "            'arrowstyle': '-|>',\n",
    "        },\n",
    "        va='center',\n",
    "        **annotation.get('kwargs', {}),\n",
    "    )\n",
    "    print(annotation['label'], item.uwwName)\n",
    "\n",
    "ax3 = ax = fig.add_subplot(gs[:, 1])\n",
    "target = lambda x: np.median(np.abs(np.log10(x.norm_area_covered / x.uwwLoadEnteringUWWTP)))\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "ys = []\n",
    "for year, subset in tqdm(merged.groupby('year')):\n",
    "    x.append(year)\n",
    "    # Evaluate the statistic.\n",
    "    y.append(target(subset))\n",
    "    # Run a bootstrap sample.\n",
    "    ys.append([target(subset.iloc[np.random.randint(len(subset), size=len(subset))])\n",
    "               for _ in range(1000)])\n",
    "\n",
    "ys = np.asarray(ys)\n",
    "l, u = np.percentile(ys, [25, 75], axis=1)\n",
    "ax.errorbar(x, y, (y - l, u - y), marker='.')\n",
    "ax.ticklabel_format(scilimits=(0, 0), axis='y', useMathText=True)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Median absolute\\n$\\\\log_{10}$ error')\n",
    "ax.xaxis.set_ticks([2006, 2008, 2010, 2012, 2014, 2016])\n",
    "plt.setp(ax.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "ax.text(0.95, 0.95, '(b)', transform=ax.transAxes, ha='right', va='top')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('population-estimates.pdf')\n",
    "\n",
    "# Show the log10 median absolute error over time.\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to illustrate why we're using area covered.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "xmin = 515000\n",
    "xmax = 523000\n",
    "ymin = 170000\n",
    "ymax = 176000\n",
    "box = shapely.geometry.box(xmin, ymin, xmax, ymax)\n",
    "\n",
    "# Plot the catchments.\n",
    "idx_catchment = catchments.sindex.query(box)\n",
    "subset = catchments.iloc[idx_catchment].sort_values('name')\n",
    "subset = subset[subset.intersection(box).area > 10]\n",
    "colors = ['C0', 'C1', 'C2']\n",
    "subset.intersection(box).plot(ax=ax, color=colors)\n",
    "\n",
    "# Plot the LSOAs.\n",
    "idx = lsoas.sindex.query(box)\n",
    "lsoas.iloc[idx].plot(ax=ax, facecolor='none', edgecolor='k', alpha=.1)\n",
    "lsoas.loc[['E01003817']].plot(ax=ax, facecolor=(.5, .5, .5, .25), edgecolor='k')\n",
    "\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_axis_off()\n",
    "handles = [mpl.patches.Rectangle((0, 0), 1, 1, color=color) for color in colors]\n",
    "labels = subset.name.str.replace(' STW', '').str.title()\n",
    "ax.legend(handles, labels)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('estimation_method.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
